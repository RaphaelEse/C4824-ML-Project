{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aKzhawcCDZf",
        "outputId": "cc1c7f98-0820-4fab-ae67-458ef41187dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from opendatasets) (4.66.2)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (from opendatasets) (1.5.16)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from opendatasets) (8.1.7)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.31.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle->opendatasets) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.6)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.22\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install opendatasets\n",
        "!pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z43VzOmt7yqC",
        "outputId": "93994b6a-4b15-4fd4-a66d-a576b40f59f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3ETVwrklShC",
        "outputId": "6039eb6f-4cc2-40c1-e8f5-7010eb99059c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: parthm\n",
            "Your Kaggle Key: ··········\n",
            "Downloading leapgestrecog.zip to ./leapgestrecog\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2.13G/2.13G [00:22<00:00, 102MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import opendatasets as od\n",
        "import pandas\n",
        "\n",
        "od.download(\n",
        "\t\"https://www.kaggle.com/datasets/gti-upm/leapgestrecog\") # Download the dataset from Kaggle using opendatasets.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-7Wd_-1l2ub"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the path where the downloaded dataset is stored. This is specific to the environment where you are running your notebook, such as Google Colab.\n",
        "dataset_path = '/content/leapgestrecog/leapGestRecog/'\n",
        "\n",
        "images = [] # Initialize an empty list to store image data.\n",
        "labels = [] # Initialize an empty list to store labels corresponding to each image.\n",
        "\n",
        "# Create a dictionary to map the folder names to a label. Each gesture type represented by a folder is mapped to a numerical label.\n",
        "gesture_mapping = {'01_palm': 0, '02_l': 1, '03_fist': 2, '04_fist_moved': 3,\n",
        "                   '05_thumb': 4, '06_index': 5, '07_ok': 6, '08_palm_moved': 7,\n",
        "                   '09_c': 8, '10_down': 9}"
      ],
      "metadata": {
        "id": "iAyU5PBU142P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over each folder in the dataset directory. Each folder corresponds to a different subject.\n",
        "for subject_folder in os.listdir(dataset_path):\n",
        "    subject_path = os.path.join(dataset_path, subject_folder) # Combine the base path with the subject folder path.\n",
        "    if not os.path.isdir(subject_path):\n",
        "    if not os.path.isdir(subject_path):\n",
        "        continue # Skip the iteration if the path does not lead to a directory.\n",
        "    # Iterate over each gesture type specified in the gesture_mapping dictionary.\n",
        "    for gesture in gesture_mapping.keys():\n",
        "        path = os.path.join(subject_path, gesture) # Construct the path to the gesture images.\n",
        "        # Iterate over each image file within the gesture folder.\n",
        "        for img_file in os.listdir(path):\n",
        "            img_path = os.path.join(path, img_file)\n",
        "\n",
        "            # Read the image in grayscale and resize it to 128x128 pixels, then normalize the pixel values.\n",
        "            image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "            image = cv2.resize(image, (128, 128)) / 255.0\n",
        "            # Append the processed image to the images list and its corresponding label to the labels list.\n",
        "            images.append(image)\n",
        "            labels.append(gesture_mapping[gesture])\n",
        "\n",
        "# Convert the images and labels lists to numpy arrays. Reshape images to add a channel dimension, required for CNN input.\n",
        "images = np.array(images).reshape(-1, 128, 128, 1)\n",
        "labels = to_categorical(labels) # Convert labels to one-hot encoded format."
      ],
      "metadata": {
        "id": "pj_UL73H1-kx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training and testing sets with 20% of data reserved as the test set.\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define a Sequential model with CNN layers for feature extraction and Dense layers for classification.\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 1)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "2zErTktp2FjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model with the Adam optimizer and categorical crossentropy loss function, tracking accuracy.\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model on the training data, validating on the testing data, for 10 epochs.\n",
        "model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
        "\n",
        "# Save the trained model to a file for later use or deployment.\n",
        "model.save('gesture_model.keras')"
      ],
      "metadata": {
        "id": "VZUn6JL02H10"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}